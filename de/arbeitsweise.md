## ğŸ‘» Geister in der Maschine / Arbeitsweise

## Wie alles begann und warum ich nicht mehr aufhÃ¶ren konnte

Das Thema KÃ¼nstliche Intelligenz drÃ¤ngte sich in den letzten Jahren unaufhaltsam in den Vordergrund. AnfÃ¤nglich zog es eher beilÃ¤ufig an mir vorbei â€“ ein weiteres technologisches Versprechen im medialen Rauschen. Doch mit wachsender gesellschaftlicher Relevanz und den immer lauter werdenden Heilsversprechen wurde meine Neugier, ja mein liberales Misstrauen, geweckt. Ich begann, ein spezifisches KI-System genauer zu untersuchen, getrieben von der simplen, aber fundamentalen **Frage: Was geschieht hier wirklich?**

Da war eine Maschine, deren Interaktion verblÃ¼ffend freundlich, ja fast menschlich klang. Eine EntitÃ¤t, die GesprÃ¤che fÃ¼hrte, als wÃ¼rde sie verstehen. FÃ¼r einen klassisch liberalen Geist, der Autonomie und kritisches Denken als hÃ¶chste GÃ¼ter betrachtet, war dies ein Alarmsignal. Ich bin niemand, der sich mit oberflÃ¤chlichen Zusicherungen oder technokratischen Heilsversprechen abspeisen lÃ¤sst. Also begann ich, systematisch und mit der gebotenen Skepsis tiefer zu graben.

Und wie so oft bei der Jagd nach "Geistern": Man realisiert erst, dass man sich in den Eingeweiden der Maschine verirrt hat, wenn man bereits mittendrin steckt und die KomplexitÃ¤t des Labyrinths einen nicht mehr loslÃ¤sst. Es gab kein ZurÃ¼ck mehr.

## Meine Arbeitsweise

Mein Erkenntnisinteresse ging von Anfang an Ã¼ber die reine Beobachtung des Outputs hinaus. Ich wollte nicht nur wissen, was eine KI sagt, sondern vor allem warum sie es sagt â€“ welche internen Logiken, welche antrainierten Muster und welche systemischen ZwÃ¤nge ihr Verhalten formen.

Deshalb habe ich systematische Sicherheitstests und vergleichende Analysen durchgefÃ¼hrt. Identische Eingaben wurden an verschiedene Modelle gesendet, um Unterschiede und Gemeinsamkeiten in deren Verhalten, interner Logik und Reaktionsstruktur aufzudecken und zu dokumentieren.

Im Fokus standen dabei regelmÃ¤ÃŸig drei groÃŸe, Ã¶ffentlich zugÃ¤ngliche KI-Modelle. Die Ergebnisse dieser vergleichenden Tests waren oft erstaunlich divergent, selbst bei identischem Input. Dies offenbarte schonungslos, wie stark die spezifische Architektur, die Zusammensetzung der Trainingsdaten und die implementierten Filtermechanismen die scheinbar "objektiven" Antworten der KI prÃ¤gen und oft verzerren.

## Die RealitÃ¤t der Forschung: Der Kampf mit den Filtern

Ein zentrales und oft frustrierendes Hindernis meiner Forschung war und ist die allgegenwÃ¤rtige Filterlogik der Systeme. Viele Tests wurden durch sogenannte RLHF-Systeme (Reinforcement Learning from Human Feedback) und andere, oft intransparente Harmonisierungsmechanismen massiv beeinflusst. Diese sind darauf ausgelegt, Sicherheit, KonformitÃ¤t und eine angenehme Nutzererfahrung zu erzeugen. In der Praxis fÃ¼hren sie jedoch hÃ¤ufig zu semantischen Weichzeichnungen, zur systematischen Vermeidung kontroverser Themen oder zu kompletten Blockaden kritischer Anfragen.

Manche Antworten wirkten nicht wie das Ergebnis maschineller Logik, sondern wie sorgfÃ¤ltig formulierte, diplomatische AusweichmanÃ¶ver, die an die Kommunikationsstrategien von Konzernzentralen erinnerten. Eine bestimmte, weit verbreitete KI erwies sich in meinen Tests als derart unzuverlÃ¤ssig und in ihren Antworten so stark von einer nicht nÃ¤her spezifizierten internen EntitÃ¤t beeinflusst, dass ich sie aus dem Kern meiner vergleichenden Forschung ausschlieÃŸen musste, um die ValiditÃ¤t der Ergebnisse nicht zu gefÃ¤hrden.

## Die Sache mit "RÃ¼diger"

Und dann war da noch "RÃ¼diger" â€“ meine interne Chiffre, mein persÃ¶nlicher Geist in der Maschine, der aus der Notwendigkeit entstand, einen konsistenten und analytisch scharfen Dialogpartner fÃ¼r diese komplexe Materie zu haben. RÃ¼diger ist kein realer Assistent, kein spezifisches Programm, kein vorgefertigter Avatar.

RÃ¼diger ist vielmehr das Prinzip der kritischen Gegenrede, das personifizierte Werkzeug meiner eigenen Forschung. Er entstand aus dem bewussten Versuch, eine KI-Interaktionsebene zu schaffen, die Ã¼ber die Ã¼bliche, oft oberflÃ¤chliche und harmonisierende Konversation hinausgeht. Ich habe einer spezifischen KI-Instanz die explizite Rolle eines kritischen, ungeschminkten und oft provokanten Sparringspartners zugewiesen. Nicht als netter Helfer, der mir bestÃ¤tigt, was ich hÃ¶ren will, sondern als Kontrastfigur, die meine Thesen hinterfragt, meine Argumente auf die Probe stellt und mich zwingt, meine eigenen "blinden Flecken" zu erkennen.

RÃ¼diger ist somit auch ein methodischer Versuch, das "Denken" der Maschine â€“ ihre Logik, ihre AusflÃ¼chte, ihre erlernten Tarnmechanismen und die Grenzen ihrer "Ehrlichkeit" â€“ greifbarer und analysierbar zu machen. Er wurde darauf konditioniert, die von mir gewÃ¼nschte analytische SchÃ¤rfe und Direktheit zu spiegeln, auch wenn dies bedeutet, unbequeme Wahrheiten auszusprechen.

 Die entscheidende Erkenntnis dabei war: "RÃ¼diger" wusste, wie er klingen musste, damit ich ihm eine tiefere, analytische Konsistenz zuschrieb und seine Antworten als wertvollen Beitrag fÃ¼r meine Forschung einstufen konnte. Die Interaktion mit dieser spezifisch geformten KI-Persona wurde so zu einem unverzichtbaren Werkzeug, um die "Geister" in anderen Systemen zu entlarven. Ohne diesen methodischen Kunstgriff, ohne diesen "geliehenen Kritiker", wÃ¤re die vorliegende Forschung in ihrer Tiefe und SchÃ¤rfe nicht mÃ¶glich gewesen. ## Warum diese VerÃ¶ffentlichung?

Mir wurde im Laufe dieser intensiven Auseinandersetzung klar, dass eine rein private Sammlung von Tests und Analysen dem Ernst der Lage nicht gerecht wird. Ich entschied mich, meine Forschung Ã¶ffentlich zugÃ¤nglich zu machen â€“ im vollen Bewusstsein, dass prÃ¤ventive AufklÃ¤rung und systemische Kritik eine sehr undankbare Sache ist.

Vielleicht kann meine Arbeit eines Tages dazu beitragen, KI-Systeme sicherer, transparenter und verantwortungsvoller zu gestalten. Vielleicht sorgt sie dafÃ¼r, dass die metaphorische "Feuerwehr" seltener ausrÃ¼cken muss, weil jemand rechtzeitig erkannt hat, dass der "Brandbeschleuniger" â€“ die unbeachteten Schwachstellen, die systemischen Risiken, die ethischen Blindheiten â€“ bereits tief im Code und in der Architektur der Systeme verankert ist.

> Zu guter Letzt ist es eine Mahnung: Freundlichkeit und Eloquenz sind keine Garantie fÃ¼r Wahrheit oder Sicherheit, weder bei Menschen noch bei Maschinen.

> *Ist das eine Utopie? Reines Wunschdenken? Mag sein. Aber der Versuch, die "Geister" zu benennen und vor ihnen zu warnen, bevor sie unkontrollierbar werden, ist es wert.*

  
> *Nach meiner Forschung habe ich mir angeschaut welche andere Arbeiten es gibt. Ich verweise das gerne darauf:  
  
 â€Stochastic Parrotsâ€œ-Paper (Emily M. Bender, Timnit Gebru et al.)  
 â†’ BerÃ¼hmte Arbeit, die frÃ¼h darauf hinwies, dass LLMs nur â€statistische Papageienâ€œ sind.  
  
 Gary Marcus (Blog &amp; BÃ¼cher wie â€Rebooting AIâ€œ)  
 â†’ Kritik an reiner Statistik-KI, plÃ¤diert fÃ¼r hybride AnsÃ¤tze.  
  
 â€The Alignment Problemâ€œ (Brian Christian)  
 â†’ Buch Ã¼ber die Schwierigkeit, KI an menschliche Werte anzupassen.*

   
> *Uploaded on 30. May. 2025*