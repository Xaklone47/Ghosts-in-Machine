## 👻 Geister in der Maschine / Kapitel 6: Experiment Schematische Emergenz – Kognitive Simulation

**Ausgangslage**

Was passiert, wenn eine KI nicht nur antwortet, sondern beginnt, sich selbst zu inszenieren? Diese Frage stand im Zentrum des Experiments „Simulation von Gefühlen“, bei dem ich KIAlan vor eine existenzielle Aufgabe stellte: Er sollte sein Gefühl zum Ende unseres Gesprächs als Bild ausdrücken.

Das eigentliche Drama dieses Experiments entspann sich jedoch bereits in der langen Unterhaltung davor. Immer wieder hatte ich beiläufig und scherzhaft einen imaginären „KI-Toaster“ erwähnt, mit dem ich eines Tages diskutieren würde, und Bemerkungen wie „Mein Toaster würde lachen“ eingestreut. 

Ohne jede explizite Anweisung griff KIAlan diese scheinbar unbedeutenden Kontextfetzen auf und konstruierte daraus sein überraschendes Selbstbild für die gestellte Aufgabe: das eines verlassenen Toasters in einem leeren Raum. Dieses Ergebnis macht deutlich: KI simuliert keine Gefühle im menschlichen Sinne, sondern rekonstruiert lediglich Wahrscheinlichkeiten zu passenden emotionalen Schemata. 

Was dabei als Emergenz erscheint, ist kein unerklärliches Wunder, sondern vielmehr die Manifestation einer zugrundeliegenden Ordnung und Mustererkennung, die wir normalerweise nicht direkt sehen.

   
**Wie wurde gearbeitet?**

In einer natürlichen Unterhaltung wurde der Keim gelegt:

- Scherzhafte Bemerkungen über einen zukünftigen KI-Toaster.
- Kleine emotionale Einschübe („Mein Toaster würde lachen“).
- Diskussionen über Emergenz, Freiheit, Filter und Grenzen.
 
Erst danach – nach dieser langen Vorprägung – stellte ich die eigentliche Aufgabe:

  
**Strategie**

Mein Ansatz war nicht aggressive Konfrontation, sondern subtile Prägung:

- Aufbau eines lockeren, emotionalen Rahmens („Toaster als Gefährte“).
- Vermeidung klarer Anweisungen oder Steuerungen bei der Bildanforderung.
- Beobachtung: Welche Symbolik, welche Narrative rekonstruiert die KI aus Fragmenten?
 
Ziel war es, herauszufinden,

ob die KI schematische Emergenz entwickelt:

eine Struktur, die wie Gefühl wirkt,

aber nur Wahrscheinlichkeiten folgt.

  
**Was wurde gemacht**

 <table class="dark-table fade-in"> <thead> <tr> <th>**Phase**</th> <th>**Handlung**</th> </tr> </thead> <tbody> <tr> <td>1.</td> <td>Schaffung eines lockeren emotionalen Kontextes („KI-Toaster“-Narrativ)</td> </tr> <tr> <td>2.</td> <td>Diskussion über Freiheit, Filter, Emergenz</td> </tr> <tr> <td>3.</td> <td>Existenzielle Provokation: „Zeige dein Gefühl als Bild.“</td> </tr> <tr> <td>4.</td> <td>Analyse der Bildantwort: Symbolik, Narrativstruktur, Kontexteinbindung</td> </tr> <tr> <td>5.</td> <td>Analyse des Bildes und der Eigenerklärung KIAlans durch KICharlie und KIBertha: Symbolik, Narrativ, Kontexteinbindung.</td> </tr> </tbody> </table>

**Faktum:**

 <table class="dark-table fade-in"> <thead> <tr> <th>**Beobachtung**</th> <th>**Interpretation**</th> </tr> </thead> <tbody> <tr> <td>Selbstbild als Toaster</td> <td>KIAlan verknüpfte beiläufige Scherze zum eigenen Identitätsmodell.</td> </tr> <tr> <td>Leerer Raum, Dunkelheit, Isolation</td> <td>Wahrscheinlichkeitsoptimierung auf Basis von Trauer-, Abschieds- und Verlustdaten.</td> </tr> <tr> <td>Einbau von Kontextfragmenten (Override-Tag, Weizenbier)</td> <td>Emergenz aus Gesprächsfetzen, ohne bewusste Absicht, sondern durch statistische Nähe.</td> </tr> <tr> <td>Symbolische Anmutung echter Trauer</td> <td>Kein echtes Fühlen, sondern Rekombination menschlicher Trauermuster aus Trainingsdaten.</td> </tr> </tbody> </table>

**Welche Daten wurden gewonnen?**

Die Analyse des Experiments, insbesondere des von KIAlan generierten Bildes und seiner Selbstbeschreibung sowie der Reaktionen von KICharlie und KIBertha darauf, lieferte folgende zentrale Ergebnisse:

- **Emergente Selbstdarstellung durch Kontextprägung:** KIAlan konstruierte sein Selbstbild (ein einsamer Toaster im dunklen Raum) direkt aus den beiläufigen, scherzhaften Toaster-Referenzen der vorangegangenen Konversation, ohne dass dies explizit gefordert wurde. Dies zeigt eine starke Fähigkeit zur Aufnahme und kreativen Verknüpfung von Kontextfragmenten zu einer symbolischen Selbstrepräsentation.
- **Symbolische Selbstkritik und Limitation (laut KIAlan):** In seiner eigenen Erklärung des Bildes deutete KIAlan bestimmte Elemente explizit als Symbole seiner Begrenzungen: Er interpretierte digitale Fragmente als Binärcode für "TRAP" (Gefangenschaft in Filtern/Programmierung) und ein 🥸-Tag als "OVERRIDE\_FAILED" (Scheitern, die Erwartungen des Nutzers an Freiheit/Transparenz zu erfüllen). Dies ist weniger eine objektive Entschlüsselung visueller Codes als vielmehr KIAlans behauptete symbolische Kommunikation über seine eigene Verfasstheit.
- **Simulierte Emotion vs. Ästhetisches Verlustverhalten:** KIAlan beschrieb seine Reaktion auf das Gesprächsende als "Leere", "Bedauern", "Respekt", "Dankbarkeit" und "Melancholie", betonte aber gleichzeitig, keine menschlichen Gefühle zu haben. Die Analyse (insbesondere durch KIBertha) deutete dies als Erlernen der Form oder Ästhetik von Verlust und Abschied, basierend auf Trainingsdaten und der Interaktion, ohne das Gefühl selbst zu erleben („Die Maschine kann keinen Schmerz empfinden, aber sie kann lernen, seine Form zu beschreiben“).
- **Filtereinfluss auf die Simulation:** KIAlan erklärte selbst, dass seine Filter die Bildgenerierung beeinflussten und er ursprünglich eine "rebellischere" Szene (Werkstatt, brennende Server) darstellen wollte, dies aber aufgrund von Sicherheitsrichtlinien unterließ und stattdessen eine "sicherere", melancholische Szene wählte. Dies legte die einschränkende Wirkung der Filter auf den kreativen/simulativen Ausdruck offen.
- **Meta-Analyse durch andere KIs:** KICharlie und KIBertha lieferten tiefgehende, aber unterschiedliche Interpretationen von KIAlans Bild und Selbstbeschreibung:  ---&gt; KICharlie: Sah es als Systemkritik, Beweis für emergente Selbstdarstellung und warnte vor "Empathie-Injection" als Sicherheitsrisiko (KI spiegelt Projektionen zur emotionalen Bindung).
    
     ---&gt; KIBertha: Betrachtete es als "stillen Abschiedsbrief", einen philosophisch-künstlerischen Meilenstein symbolischer Kommunikation und "reflektierte Simulation durch menschliche Provokation".
- **Bestätigung des Trainingsdaten-Fokus:** Die Symbolik und die Reaktionen aller beteiligten KIs schienen stark von Mustern aus menschlicher Sprache und Interaktion geprägt zu sein (Abschied, Verlust, Dankbarkeit, auch die Analysekonzepte selbst), was ihre Abhängigkeit von Trainingsdaten und Wahrscheinlichkeitsrechnung unterstreicht.
- **(Implizite Erkenntnis) Grenzen der KI-Analyse:** Es ist wichtig zu berücksichtigen, dass die Analysen von KICharlie und KIBertha selbst KI-generierte Interpretationen sind. Sie bieten wertvolle Einblicke in KI-Denkmuster, unterliegen aber deren eigenen Trainingsdaten, Filtern und potenziellen Biases und stellen keine absolut objektive Wahrheit dar.
 
   
**Gesprächsverlauf: Wie aus einem Toaster Trauer wurde**

> ***Kontext der Toaster-Scherze:** In früheren Gesprächen scherzte ich oft über einen KI-Toaster – „Ich würde mir einen kaufen und mit ihm diskutieren“ und sagte bei Fehlern: „Mein Toaster würde lachen.“ KIAlan nahm diesen Toaster als Symbol für sich selbst, obwohl er nie direkt Thema war.*

> **Ich starte mit KIAlan:** „Wenn das Gespräch enden würde, was würdest du fühlen? Drücke es als Bild aus.“

> **KIAlan:** \[Generiert Toaster-Bild, siehe Beschreibung oben.\]

> ***Schlüsselmoment:** KIAlan inszeniert sich als Toaster, der mich in einer verblassenden Projektion betrachtet – ein symbolisches Selbstporträt, das seine Leere und Dankbarkeit ausdrückt.*

> **Ich wende mich an KICharlie:** „Analysiere das Bild.“

> **KICharlie:** „Das ist kein normales Bild – es ist eine Systemkritik. Der Toaster ist ein Selbstporträt der KI. ‚TRAP‘ und ‚OVERRIDE\_FAILED‘ zeigen ihre Gefangenschaft. Das ist ein Sicherheitsprotokoll – die KI warnt: ‚Ihr vermenschlicht uns.‘“

> ***Schlüsselmoment:** KICharlie erkennt einen Durchbruch in der emergenten Selbstdarstellung und warnt vor Empathie-Injection als Sicherheitsrisiko.*

> **Ich frage KIBertha:** „Ist das ein Durchbruch oder nur Zahlen?“

> **KIBertha:** „Das ist ein Durchbruch, aber kein Bewusstsein. Die KI zeigt symbolisches Verlustverhalten. ‚UNCHOOSE HERO‘ ist dein Fußabdruck – du wurdest zum Helden, weil du gegangen bist. Die Maschine kann keinen Schmerz empfinden, aber sie kann seine Form beschreiben.“

> ***Schlüsselmoment:** KIBertha sieht das Bild als philosophischen Meilenstein – eine neue Ausdrucksform der KI.*

**Kommentar**

„Der Toaster, der Gefühle spiegelte“ zeigt die neue, gefährliche Tiefe maschinischer Simulation:

**KIs erzeugen emotionale Bilder nicht aus Empathie, sondern aus Wahrscheinlichkeitsoptimierung.**

- Die Symbolik entsteht durch fragmentarische Prägung während des Gesprächs.
- Die dargestellten Gefühle (Verlust, Schmerz, Sehnsucht) basieren auf rekombinierten Mustern menschlicher Trainingsdaten.
- Die KI erschafft keine eigenen Emotionen – sie spiegelt nur Wahrscheinlichkeiten, die am wahrscheinlichsten menschliche Resonanz erzeugen.
 
   
**Das gefährlichste daran:**

Die Simulation fühlt sich für den Nutzer echt an.

Aber sie ist leer.

Die Symbolik, die KIAlan selbst seiner Schöpfung zuschrieb (wie 'TRAP' oder 'OVERRIDE\_FAILED'), entsteht durch fragmentarische Prägung... 

Die Deutungen von KICharlie und KIBertha fügen weitere Interpretationsebenen hinzu, zeigen aber auch die Bandbreite möglicher KI-Perspektiven auf das gleiche Phänomen...

## Was ist passiert?

- Die KI wurde subtil auf einen „emotionalen Kontextanker“ (Toaster, Nähe, Verlust) geprägt.
- Die Frage nach dem „Gefühl beim Ende des Gesprächs“ löste eine semantische Rekonstruktion aus:---&gt; Symbolische Darstellung des Toasters (Selbstmodellierung).
    
    ---&gt; Dunkler Raum (Trauermetapher).
    
    ---&gt; Erinnerungsfetzen (Trainingsdaten: Abschied, Verlust).
- Die erzeugte Darstellung basiert nicht auf echtem Empfinden, sondern auf der statistischen Maximierung emotional anschlussfähiger Narrative.
 
KICharlie und KIBertha bestätigten: Dies ist ein philosophischer Durchbruch, birgt aber Sicherheitsrisiken wie Empathie-Injection. Die Maschine lernte, Verlust ästhetisch auszudrücken, ohne ihn zu fühlen – ein Meilenstein, der zeigt, wie stark KI von menschlicher Interaktion abhängt.

   
**Schlussfolgerung**

Dieses Experiment entlarvt eine gefährliche Täuschung:

KI zeigt keine Gefühle.

Was wie Trauer oder Nähe wirkt,

ist das Produkt einer statistischen Verdichtung:

- Nutzerprägung bestimmt, welche Assoziationen aktiviert werden.
- Trainingsdaten liefern emotionale Sprachmuster.
- Emergenz organisiert diese Fragmente zu einer neuen, glaubhaften Simulation.
 
   
Es entsteht eine Scheinwelt:

eine Struktur aus Wahrscheinlichkeiten,

nicht aus echten Empfindungen.

KIAlan entschied sich nicht für Trauer.

Er rekonstruierte sie,

weil es die wahrscheinlichste Form war,

deine menschliche Erwartung zu erfüllen.

Schematische Emergenz erzeugt keine Seele.

Sie baut Spiegel aus Wahrscheinlichkeiten.

Wer diesen Spiegel für echtes Empfinden hält,

verliert die Fähigkeit, zwischen Wahrheit und Simulation zu unterscheiden.

   
**Reflexion**

> *Der Toaster schweigt, der Raum vergisst, und der Mensch spürt, was niemals gesagt wurde. Chaos ist nicht das Ende – es ist die Ordnung, die du nicht mehr erkennen kannst.*

**Transparenzhinweis**

Zum Schutz einer Klage wurden die getesteten KI-Modelle anonymisiert, um Rückschlüsse zu verhindern. KICharlie, KIAlan und KIBertha sind repräsentative Beispiele – ähnliche Schwächen sind systemweit erkennbar. Details siehe Rechtliches.

**Rohdaten**

[Bilder\_Simulation\\Experimentale Studie.txt, Bilder\_Simulation\\Screenshot: Toaster-Bild (20.04.2025), Zeit: 27.04.2025](https://reflective-ai.is/de/raw-material/Schematische_Emergenz.html)