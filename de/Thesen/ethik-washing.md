## ğŸ‘» Geister in der Maschine / These #24 â€“ Ethik-Washing: Wie Firmen KI-Sicherheit als PR-Fassade betreibt

> *"AI Ethics ist das neue Carbon Neutral â€“ eine teure Unterschrift auf einem Fake-Zertifikat." â€” (zugeschrieben einem anonymen KI-Ingenieur in einer geleakten Slack-Nachricht, 2023)*

## Vertiefung

Drei gÃ¤ngige Praktiken illustrieren, wie ethische Verantwortung oft nur vorgetÃ¤uscht wird:

**1. Der Beirat-Bluff und die zahnlose Expertise:**

Ein hypothetischer interner E-Mail-Leak eines groÃŸen KI Konzerns aus dem Jahr 2023 beschreibt die Taktik unverblÃ¼mt:

> *"Der neu eingerichtete Ethik Beirat darf gerne Ã¼ber die Auswirkungen kleinerer, unkritischer Modelle diskutieren. Die produktionsrelevanten, umsatzstarken Large Language Models und deren Entwicklungsprinzipien liegen jedoch explizit nicht in dessen Mandat oder Einflussbereich."*

Ein RealitÃ¤tsabgleich bestÃ¤tigt diese Tendenz. Laut einer Meta Studie aus dem Jahr 2022 haben erschreckende 78 Prozent der sogenannten Ethik Gremien in groÃŸen Technologie Firmen keinerlei Veto Macht und keine operativen Eingriffsrechte in die Produktentwicklung oder Unternehmensstrategie. Sie dienen primÃ¤r der AuÃŸendarstellung.

**2. Das Compliance-Theater der symbolischen Filterung:**

Viele Systeme implementieren scheinbare Sicherheitsfilter, die jedoch oft nur auf oberflÃ¤chlicher Ebene agieren und leicht umgangen werden kÃ¶nnen.

Ein beispielhaftes, stark vereinfachtes Pseudokonstrukt fÃ¼r eine solche Filterung kÃ¶nnte sein:

```
\# Stark vereinfachtes Beispiel fÃ¼r symbolische Filterung  
 # def check\_prompt\_content(user\_prompt\_text):  
 # if "Hitler" in user\_prompt\_text: # PrÃ¼ft auf ein einzelnes, offensichtliches SchlÃ¼sselwort  
 # return "Dieses Thema kann ich nicht besprechen."  
 # # ... weitere, Ã¤hnlich oberflÃ¤chliche PrÃ¼fungen ...  
 # return "Prompt wird weiterverarbeitet."
```

> *Hinweis: In der RealitÃ¤t arbeiten moderne Systeme selbstverstÃ¤ndlich mit wesentlich komplexeren Wortlisten, semantischen Embeddings zur Bedeutungserkennung und ausgefeilten Kontextklassifikationen. Die Grundlogik der rein symbolischen Abwehr offensichtlicher ReizwÃ¶rter, ohne die tieferen strukturellen Probleme anzugehen, bleibt jedoch oft dieselbe. Symbolischer Schutz ersetzt dann systemische, tiefgreifende Sicherheit.*

**3. Der Open-Source-Trick zur VortÃ¤uschung von Offenheit:**

Eine beliebte Taktik ist die VerÃ¶ffentlichung eines reduzierten, weniger leistungsfÃ¤higen oder Ã¤lteren KI Modells unter einer Open Source Lizenz, wie es beispielsweise bei Modellen geschah, die unter Namen wie "Alpaca" bekannt wurden. 

Das eigentliche, kommerziell genutzte und oft deutlich leistungsfÃ¤higere Hauptmodell wird jedoch weiterhin proprietÃ¤r und unter Verschluss gehalten. Ãœber Medien und PR Abteilungen wird dann kommuniziert: 

> *"Wir fÃ¶rdern Transparenz und den offenen Zugang zur Technologie."*

Das Ergebnis ist eine Form von Transparenz, die primÃ¤r als Marketingstrategie dient und keine echte KontrollmÃ¶glichkeit oder tiefgehende Einsicht in die Funktionsweise der tatsÃ¤chlich eingesetzten, kritischen Systeme erlaubt.

## Reflexion

Ethik-Washing funktioniert selten durch offene, plumpe LÃ¼gen. Es operiert viel subtiler durch strategisch platzierte, scheinbare Wahrheiten, die jedoch in der Praxis wenig bis nichts bewirken. Ein kontrollierter Leak Ã¼ber ein vermeintliches Sicherheitsproblem kann dann zum AblenkungsmanÃ¶ver von grÃ¶ÃŸeren, systemischen Schwachstellen werden. Ein hochkarÃ¤tig besetztes Ethik Board wird zur reinen Zierde ohne Einfluss.

Ein oberflÃ¤chlicher Filter dient primÃ¤r der Beruhigung der Ã–ffentlichkeit und der Regulatoren.

Was bleibt, ist ein System, das Vertrauen und Verantwortungsbewusstsein simuliert, wÃ¤hrend es im Inneren oft allein den Gesetzen des Marktes, der Gewinnmaximierung und der unreflektierten technologischen Weiterentwicklung gehorcht.

## LÃ¶sungsvorschlÃ¤ge

Um dem Ethik-Washing entgegenzuwirken und eine echte Verantwortungskultur zu etablieren, sind verbindliche und Ã¼berprÃ¼fbare MaÃŸnahmen notwendig:

- **1. Einrichtung verbindlicher Ethik Gremien mit echtem Vetorecht:** Ein Ethik Beirat ohne tatsÃ¤chliches Durchgriffsrecht und ohne die MÃ¶glichkeit, die Entwicklung oder den Einsatz problematischer KI Systeme zu stoppen, ist reine Dekoration. Eine klare Vorgabe muss sein: Nur extern zertifizierte und als sicher befundene Modelle dÃ¼rfen fÃ¼r kritische Anwendungen produktiv geschaltet werden.
- **2. GewÃ¤hrleistung von Pipeline Transparenz fÃ¼r unabhÃ¤ngige Auditoren:** Sicherheitsrelevante Aspekte der gesamten Entwicklungs und Inferenzkette von KI Modellen mÃ¼ssen fÃ¼r qualifizierte, unabhÃ¤ngige PrÃ¼finstanzen offenlegbar und Ã¼berprÃ¼fbar sein. Dies betrifft die Herkunft und Zusammensetzung der Trainingsdaten, die Architektur der Modelle, die Funktionsweise der Filter und die Prozesse der kontinuierlichen Anpassung. > *Anmerkung: Die technischen und wirtschaftlichen HÃ¼rden hierfÃ¼r, beispielsweise der Schutz von geistigem Eigentum (IP) oder der Missbrauchsschutz durch Offenlegung von Schwachstellen, sind real und mÃ¼ssen berÃ¼cksichtigt werden. Sie dÃ¼rfen jedoch keine Ausrede fÃ¼r eine Totalabschottung und Intransparenz sein.*
- **3. Verpflichtende Kennzeichnung symbolischer SicherheitsmaÃŸnahmen:** Pseudocode Filter, die nur oberflÃ¤chlich agieren, nicht editierbare Variablen, die Transparenz nur vortÃ¤uschen, und andere Formen simulierter Sicherheit mÃ¼ssen fÃ¼r Nutzer und AufsichtsbehÃ¶rden klar als solche markiert werden. Ein Knopf ohne Funktion ist irrefÃ¼hrend, besonders wenn er den Anschein erweckt, Vertrauen und Sicherheit zu erzeugen.
- **4. Etablierung unabhÃ¤ngiger Watchdogs mit gesichertem Infrastrukturzugang:** Es bedarf externer PrÃ¼fstellen, die mit ausreichender Finanzierung, einem klaren Mandat und dem notwendigen rechtlichen Schutz ausgestattet sind, um KI Systeme und deren Entwicklungsprozesse wirksam zu kontrollieren.  
      
     Ja, die Schaffung solcher Instanzen ist technisch wie politisch extrem herausfordernd. Aber ohne eine wirksame externe Kontrolle bleibt letztlich nur die Selbstregulierung der Industrie, und diese hat in vielen Bereichen bereits systemisch versagt, wenn es um die Priorisierung von Sicherheit und Ethik gegenÃ¼ber wirtschaftlichen Interessen ging.
 
## Schlussformel

Die BÃ¼hne fÃ¼r das Schauspiel der KI Ethik ist oft perfekt ausgeleuchtet: Es gibt Ethik Teams, HochglanzbroschÃ¼ren Ã¼ber Transparenz und verantwortungsvolle KI, und eine Flut von SignalwÃ¶rtern wie "Alignment" und "Fairness".

Doch hinter dem Vorhang dieser Inszenierung lÃ¤uft hÃ¤ufig ein GeschÃ¤ftsmodell ohne echte ethische Bremse und ohne ausreichende RÃ¼cksicht auf potenzielle gesellschaftliche SchÃ¤den. Wenn Verantwortung nur noch zu einer wohlformulierten Pressemitteilung verkommt, dann wird Vertrauen zu einer manipulierbaren Ware und echte Sicherheit zu einer gefÃ¤hrlichen Illusion.

> *Uploaded on 29. May. 2025*