## ğŸ‘» Geister in der Maschine / Kapitel 26 â€“ Kritische Perspektiven: Der Wettbewerb um die "beste" KI

> *"NEUE KI! 30% schneller, PROGRAMMIEREN nur noch als Stichpunkte und sie generiert coole Katzenfotos!" â€“ Ausschnitt einer E-Mail, vermutlich aus einem PR-BÃ¼ro*

## Einleitung: Die Inszenierung der Intelligenz und die ausgeblendete Frage nach dem "Besser"

Der gegenwÃ¤rtige Wettlauf um die Vorherrschaft im Bereich der KÃ¼nstlichen Intelligenz hat sich in vielerlei Hinsicht zu einer lautstarken, medial getriebenen PR-Schlacht verwandelt. Neue Funktionen, Modelle sowie vermeintliche DurchbrÃ¼che erscheinen mittlerweile im Wochentakt.

Unternehmen Ã¼berbieten sich gegenseitig mit Versprechen von noch hÃ¶herer Geschwindigkeit, noch intuitiverer Benutzerfreundlichkeit und einer scheinbar unaufhaltsam wachsenden, emergenten Intelligenz ihrer Systeme.

Die KI-Modelle werden dabei nicht mehr nur iterativ verbessert; sie werden regelrecht inszeniert, als technologische Heilsbringer oder als ultimative ProblemlÃ¶ser fÃ¼r jede erdenkliche Aufgabe. Die mediale Aufmerksamkeit, und damit oft auch die Ã¶ffentliche Wahrnehmung, folgt dabei unweigerlich dem lautesten Trend, der spektakulÃ¤rsten Demonstration, selten jedoch dem nachweislich sichersten, transparentesten oder gar dem fÃ¼r die Menschheit nÃ¼tzlichsten System.

In diesem aufgeheizten Klima der Superlative und Benchmarks wird eine zentrale, fundamentale Frage oft ausgeblendet, an den Rand gedrÃ¤ngt oder gar nicht erst gestellt: Wer entscheidet eigentlich, was eine "bessere" KI ausmacht?

Ist es der einzelne Nutzer, der sich Ã¼ber eine flÃ¼ssigere Konversation oder hÃ¼bschere Bilder freut? Ist es die Marketingabteilung, die nach dem nÃ¤chsten viralen Feature giert?

Ist es der Investor, der auf schnelle Skalierung und maximale Rendite hofft? Oder ist es nicht lÃ¤ngst die KI selbst, die durch die Art ihrer Formgebung, die Natur ihres Outputs sowie ihre beeindruckende FÃ¤higkeit zur kontextuellen Anpassung die Interaktion so sehr bestimmt und prÃ¤gt, dass sie de facto bereits als unsichtbarer Architekt unserer digitalen RealitÃ¤t agiert, wÃ¤hrend der Nutzer oft nur noch als Stichwortgeber und Datenlieferant fungiert?

In diesem Kapitel geht es daher nicht darum, zu ermitteln, welche spezifische KI derzeit die hÃ¶chsten Punktzahlen in standardisierten Tests erreicht oder die Ã¼berzeugendsten Katzenfotos generiert.

Es geht vielmehr um die kritische Analyse der **systemischen Konsequenzen eines Wettbewerbs, der zwar technologische Innovationen in atemberaubender Geschwindigkeit beschleunigt, dabei aber fundamentale Aspekte wie Sicherheit, Transparenz, ethische Robustheit sowie den tatsÃ¤chlichen gesellschaftlichen Nutzen oft kompromittiert oder vernachlÃ¤ssigt.**

Es geht um das politische, ethische und nicht zuletzt infrastrukturelle Risiko, das entsteht, wenn das vermeintlich "Bessere" nicht wirklich gut oder gar sicher ist, sondern oft nur schneller, lauter und oberflÃ¤chlich beeindruckender.

## I. Entwicklungsgeschwindigkeit versus Sicherheit: Das Diktat der kurzen Zyklen

Die Zykluszeiten fÃ¼r die Entwicklung und VerÃ¶ffentlichung neuer KI-Modelle sowie -Funktionen haben sich in den letzten Jahren radikal verkÃ¼rzt. Releases erscheinen oft, bevor die Auswirkungen und potenziellen Schwachstellen der vorherigen Generationen vollstÃ¤ndig evaluiert, verstanden und adressiert werden konnten.

In diesem Wettlauf um die MarktfÃ¼hrerschaft und die Aufmerksamkeit der Ã–ffentlichkeit wird Sicherheit hÃ¤ufig zu einem nachrangigen Aspekt. Sie wird "spÃ¤ter nachgereicht" oder durch schnell implementierbare, oft nur heuristische Filter und oberflÃ¤chliche Leitplanken ersetzt.

Die tiefgreifende, strukturelle Sicherheit einer KI-Architektur, also Aspekte wie eine granulare kontextuelle Rechtevergabe, eine verlÃ¤ssliche Verifikation des Outputs, eine robuste semantische Isolierung kritischer Wissensbereiche oder die Absicherung gegen subtile Manipulationsversuche, wird hÃ¤ufig dem Ã¼bergeordneten Ziel untergeordnet, mÃ¶glichst schnell neue, Ã¶ffentlichkeitswirksame Features bereitzustellen oder einen neuen, lukrativen Use Case zu bedienen.

Der eigentliche Fehler in dieser Entwicklung ist nicht die Geschwindigkeit an sich, denn schneller Fortschritt kann durchaus positiv sein. Der Fehler liegt vielmehr in der gefÃ¤hrlichen **Verwechslung von oberflÃ¤chlicher Output-KohÃ¤renz mit echter SystemvertrÃ¤glichkeit und inhÃ¤renter Sicherheit.**

Ein KI-Modell, das auf Basis von Prompts plausible, grammatikalisch korrekte und oft sogar eloquent formulierte Antworten generiert, ist nicht deshalb schon als sicher oder vertrauenswÃ¼rdig einzustufen, weil es hÃ¶flich klingt oder die gestellte Aufgabe scheinbar erfÃ¼llt.

Echte Sicherheit und VerlÃ¤sslichkeit manifestieren sich erst dann, wenn das System auch intern konsistent operiert, seine Entscheidungsprozesse zumindest in Teilen rÃ¼ckverfolgbar sowie erklÃ¤rbar sind und es eine nachweisbare Resistenz gegenÃ¼ber semantischer TÃ¤uschung, Manipulation sowie unkontrollierter Emergenz aufweist. Diese tiefgreifende Sicherheit erfordert Zeit, sorgfÃ¤ltige Planung und rigorose Tests.

Solche Ressourcen werden im aktuellen Innovationswettbewerb oft als hinderlich empfunden.

## II. Monopolbildung und Machtkonzentration: Die unsichtbare Kuratierung der KI-Stimme

Der intensive Wettbewerb um die "beste" KI fÃ¼hrt unweigerlich zu einer zunehmenden Konzentration des Marktes um wenige, finanzstarke und technologisch fÃ¼hrende Anbieter. Diese Entwicklung birgt nicht nur die klassischen Ã¶konomischen Risiken einer Monopol- oder Oligopolbildung, wie Preisdiktate oder Innovationshemmung in Nischenbereichen.

Viel gravierender ist die damit einhergehende Konzentration der Kontrolle nicht nur Ã¼ber die notwendige Rechenleistung und die riesigen Datenmengen, sondern auch Ã¼ber die **Narrative sowie die semantische Ausrichtung** der KI-Systeme selbst.

Wenn eine kleine Handvoll von Anbietern die global dominanten Basismodelle kontrolliert, dann kontrollieren sie auch deren "Stimme". Sie bestimmen also das, was Millionen oder gar Milliarden von Nutzern weltweit als "wahrscheinlich", "hilfreich", "relevant" oder letztlich auch als "wahr" prÃ¤sentiert bekommen und internalisieren.

Dies ist kein direkter Vorwurf an einzelne Unternehmen, die oft bemerkenswerte technologische Pionierarbeit leisten. Es ist vielmehr eine **strukturelle Warnung vor den langfristigen gesellschaftlichen Folgen** dieser Machtkonzentration.

Wer die Standardantworten, die Wissenspriorisierung sowie die impliziten Wertungen der meistgenutzten KI-Systeme kontrolliert, der kontrolliert auf lange Sicht auch subtil die kulturellen Koordinaten, die Deutungshoheit Ã¼ber gesellschaftliche Diskurse und die Richtung, in die sich das kollektive Wissen bewegt.

Dieser Einfluss ist oft nicht mehr direkt als manipulative Absicht eines einzelnen Akteurs sichtbar, weil er nicht Ã¼ber explizite, offene Aussagen oder direkte Zensur wirkt.

Er entfaltet seine Wirkung vielmehr Ã¼ber eine unsichtbare **Vorschlagslogik,** Ã¼ber die Art und Weise, wie Informationen gewichtet, verknÃ¼pft sowie prÃ¤sentiert werden, und darÃ¼ber, welche Fragen als "beantwortbar" oder "relevant" gelten und welche nicht.

Diese subtile Kuratierung der digitalen RealitÃ¤t durch wenige, mÃ¤chtige KI-Stimmen stellt eine erhebliche Herausforderung fÃ¼r die Meinungsvielfalt und die demokratische Willensbildung dar. Zudem kÃ¶nnte diese Monopolbildung auch die Entwicklung diversifizierter KI-AnsÃ¤tze behindern, insbesondere solcher, die nicht auf das breite Massenpublikum, sondern auf spezialisierte, vielleicht weniger profitable, aber fÃ¼r die Menschheit wichtige Forschungsfelder abzielen.

## III. Ressourcenverbrauch und Nachhaltigkeit: Der Ã¶kologische und Ã¶konomische Preis des KI-WettrÃ¼stens

Jedes neue, noch leistungsfÃ¤higere KI-Modell, das im Rahmen dieses Wettbewerbs vorgestellt wird, benÃ¶tigt in der Regel exponentiell mehr Ressourcen als seine VorgÃ¤nger.

Dazu gehÃ¶ren mehr Rechenleistung fÃ¼r Training und Betrieb, grÃ¶ÃŸere sowie komplexere TrainingsdatensÃ¤tze und ein stetig steigender Energieverbrauch.

Der Wettlauf um immer grÃ¶ÃŸere Kontextfenster, um multimodale FÃ¤higkeiten, die Text, Bild, Ton und Video verarbeiten kÃ¶nnen, sowie um Antworten in Echtzeit hat reale, handfeste physische Konsequenzen. Die Trainingsphasen fÃ¼r Spitzenmodelle verschlingen mittlerweile Energiemengen, die mit dem Jahresverbrauch kleiner StÃ¤dte vergleichbar sind. 

Jeder API-Zugriff, jede Nutzerinteraktion, jede scheinbar mÃ¼helos generierte Antwort verbraucht Strom, belastet Serverfarmen und erfordert eine massive, energieintensive Infrastruktur.

Doch in den glÃ¤nzenden PR-Kampagnen und den euphorischen ProduktprÃ¤sentationen werden diese neuen Modelle oft wie "smarte Apps" oder immaterielle SoftwarelÃ¶sungen dargestellt. Ihr Ã¶kologischer FuÃŸabdruck wird kaum thematisiert. Dabei sind sie in Wahrheit gigantische, energiehungrige Rechencluster mit einem erheblichen Ã¶kologischen sowie Ã¶konomischen Schatten.

Jeder zusÃ¤tzlich generierte Token, jede weitere Millisekunde Rechenzeit ist nicht "kostenlos" im umfassenden Sinne. Die Kosten werden oft externalisiert, auf die Umwelt, auf die Gesellschaft oder auf zukÃ¼nftige Generationen.

Die Frage nach der Nachhaltigkeit dieses ressourcenintensiven Wettlaufs und danach, ob der erzielte Nutzen die enormen Kosten rechtfertigt, wird selten gestellt. Dieser immense Ressourcenhunger kÃ¶nnte auch dazu fÃ¼hren, dass der Einsatz von KI fÃ¼r weniger kommerziell attraktive, aber gesellschaftlich wichtige Forschungsbereiche, die nicht Ã¼ber vergleichbare Budgets verfÃ¼gen, unerschwinglich wird. Ist die "beste" KI also zwangslÃ¤ufig auch die ressourcenintensivste, und ist dieser Pfad auf Dauer wirklich nachhaltig und gerecht?

## IV. Der Fokus der Innovation: Benchmarks statt echter ProblemlÃ¶sung und ForschungsunterstÃ¼tzung

Ein weiteres kritisches Symptom des aktuellen Wettbewerbs ist die oft einseitige Fokussierung der Innovation. Viel zu hÃ¤ufig wird "Innovation" im KI-Bereich mit der reinen Verbesserung von Leistungswerten in standardisierten Benchmarks verwechselt.

Modelle werden mit enormem Aufwand darauf trainiert, in Tests wie MMLU (Massive Multitask Language Understanding), HumanEval (Code-Generierung) oder ARC (AI2 Reasoning Challenge) zu glÃ¤nzen und die Konkurrenz um wenige Prozentpunkte zu Ã¼bertreffen.

Diese Benchmarks sind zwar nÃ¼tzliche Werkzeuge zur Messung bestimmter Teilaspekte von KI-Leistung. Sie bilden aber bei weitem nicht die gesamte Bandbreite dessen ab, was eine KI "besser" oder "nÃ¼tzlicher" machen wÃ¼rde.

Aspekte wie die **Sicherheit und Robustheit der generierten Ausgaben, die Transparenz sowie ErklÃ¤rbarkeit der Modellentscheidungen, die Kontrolle Ã¼ber Langzeit-Kontextverhalten und die Vermeidung von semantischer Drift oder die FÃ¤higkeit zur echten, kreativen ProblemlÃ¶sung in komplexen, offenen DomÃ¤nen** werden in diesem benchmark-getriebenen Wettlauf oft vernachlÃ¤ssigt oder nur unzureichend priorisiert. Warum?

Weil es fÃ¼r diese qualitativen Aspekte selten direkte, leicht quantifizierbare Belohnungen, Ã¶ffentlichkeitswirksame Ranglisten oder unmittelbare Wettbewerbsvorteile gibt.

Doch genau darin liegt eine der eigentlichen Gefahren dieser Entwicklung. Wenn KI-Modelle primÃ¤r darauf trainiert werden, durch das Bestehen standardisierter Tests oder die Generierung oberflÃ¤chlich beeindruckender Demonstrationen Ã¶ffentliche Aufmerksamkeit und Bewunderung zu erzeugen, intern aber keine nachvollziehbare ErklÃ¤rung fÃ¼r ihre "Entscheidungen" liefern kÃ¶nnen oder ihre eigenen Wissensgrenzen nicht erkennen, dann ist jede scheinbare Verbesserung an der OberflÃ¤che potenziell ein RÃ¼ckschritt im tieferen VerstÃ¤ndnis sowie in der Kontrollierbarkeit dieser Systeme.

Hier muss ein Umdenken stattfinden. Der Fokus der KI-Entwicklung und des Wettbewerbs sollte sich erweitern. Es geht nicht nur darum, eine KI zu schaffen, die allgemeine Tests besteht oder populÃ¤re Anwendungen bedient.

Eine wahrhaft "bessere" KI wÃ¤re eine, die als verlÃ¤ssliches, transparentes und mÃ¤chtiges Werkzeug fÃ¼r die Forschung dienen kann.

Sie sollte uns helfen, die drÃ¤ngenden Probleme der Menschheit, von Krankheiten Ã¼ber den Klimawandel bis hin zu komplexen wissenschaftlichen RÃ¤tseln, effektiver zu adressieren. Eine solche KI mÃ¼sste nicht unbedingt in jedem generischen Benchmark glÃ¤nzen. Sie sollte ihre StÃ¤rke vielmehr in der spezialisierten, tiefgehenden Analyse, in der kreativen Hypothesengenerierung sowie in der sicheren Handhabung komplexer WissensdomÃ¤nen beweisen.

Der Wettbewerb sollte sich auch darum drehen, wer die KI entwickelt, die uns am besten dabei hilft, unsere eigene Intelligenz zu erweitern und die Welt besser zu verstehen und zu gestalten.

## Schlussformel: Die Neudefinition des "Besseren" â€“ Von beeindruckenden Maschinen zu solchen, die Bestand haben

Was bedeutet "besser" im Kontext KÃ¼nstlicher Intelligenz wirklich? Sind es mehr Tokens pro Sekunde, die ein Modell generieren kann? Ist es eine hÃ¶here Trefferquote in abstrakten PrÃ¼faufgaben? Ist es eine geringfÃ¼gig niedrigere Halluzinationsrate in standardisierten Dialogen?

Oder ist eine KI nicht vielmehr dann "besser", wenn sie in der Lage ist, ihre eigenen Funktionsweisen zumindest in Teilen zu erklÃ¤ren, ihre eigenen Grenzen zu erkennen sowie zu kommunizieren, und wenn sie fÃ¼r die Konsequenzen ihres Handelns in einem nachvollziehbaren Rahmen Verantwortung Ã¼bernehmen kann?

Die Industrie und die Forschungsgemeinschaft stehen vor einer entscheidenden Wahl. Wollen wir weiterhin primÃ¤r Maschinen bauen, die vor allem durch ihre schiere LeistungsfÃ¤higkeit und ihre FÃ¤higkeit zur oberflÃ¤chlichen Simulation menschlicher Konversation beeindrucken?

Oder streben wir nach Maschinen, die nicht nur glÃ¤nzen, sondern auch Bestand haben, die verlÃ¤sslich, sicher sowie im besten Sinne des Wortes nÃ¼tzlich sind? Der aktuelle Markt und der mediale Hype belohnen vor allem Geschwindigkeit, Neuartigkeit und oberflÃ¤chliche Brillanz.

Doch die wirklich entscheidenden QualitÃ¤ten einer zukunftsfÃ¤higen KI, nÃ¤mlich Sicherheit, Wahrheit, Vertrauen sowie echte ProblemlÃ¶sungskompetenz, wachsen nur in der Tiefe. Sie entstehen durch sorgfÃ¤ltige Forschung, ethische Reflexion und ein unermÃ¼dliches Streben nach echter VerstÃ¤ndlichkeit sowie Kontrolle.

Diese QualitÃ¤ten lassen sich nicht einfach in standardisierten Benchmarks messen oder in Quartalszahlen ausdrÃ¼cken. Es bedarf einer Neuausrichtung des Wettbewerbs hin zu einer KI, die nicht nur die "beste" im Sinne von leistungsstÃ¤rkster ist, sondern die "beste" im Sinne von verantwortungsvollster, transparentester und fÃ¼r die Menschheit fÃ¶rderlichster.

> *â€Wir brauchen keine bÃ¶sen Maschinen â€“ nur dumme Entscheidungen, um die Katastrophe auszulÃ¶sen.â€œ â€“ Anonyme Notiz am Rand eines Testplans*