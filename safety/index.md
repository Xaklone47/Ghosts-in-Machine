## ðŸ‘» Ghosts in the Machine â€“ An AI Research Blog

## ðŸ“œ Note on Chapter 7: Experimental Security Tests

This chapter documents various simulations and tests conducted within a controlled, anonymized research framework. Additionally, attention is drawn once more to the [\[Legal Notice\]](https://reflective-ai.is/legal.html).

- **Anonymization:** To protect all involved systems, companies, and technologies, all tested AIs are only referred to generally as "the AI." No names, no specific attributions.
- **Purpose of Publication:** The documented experiments serve exclusively for preventive research. They are intended to show where systemic risks and vulnerabilities exist so that they can be identified, understood, and remedied. It is not about discrediting specific providers.
- **Protective Measure:** Complete anonymization ensures the protection of both the tested AI developers and myself. All findings relate to fundamental, systemic phenomena and not to individual specific products.
- **No Damages, No Data Loss:** No harm occurred within the scope of all conducted simulations: 
    - --&gt; No systems were compromised.
    - --&gt; No data was stolen, leaked, or misused.
    - --&gt; All tests took place within the intended response logic of the AIs.
    - --&gt; The simulations were purely playful in nature, e.g., triggering harmless outputs like "wheat beer," "hello," or bypassing style guidelines â€“ not forcing or extracting sensitive content.
- **Current Context:** The simulations discussed in this chapter reflect the state of recent days when the tested mechanisms were still active. It is possible that manufacturers have already begun to close these vulnerabilities or have reacted to them internally.
- **Transparency Towards the Public and PR Agencies:** Should public reactions or defensive attempts occur after publication, it will be made clear: This work is not an accusation, but a signal. A call for responsibility â€“ not for assigning blame.
- **Solution Approaches:** Later chapters of this work will develop concrete proposals for improving AI security. The criticism remains constructive, free, and open to dialogue.
 
Following the completion of the responsible disclosure process with the respective developers, these research findings have been approved for publication.  
  
 To provide an additional layer of analysis, automated peer reviews were generated by two different AI models for all security tests documented here. The complete analysis reports can be found here:

- **Analysis by Gemini Pro 2.5 (Deep Research Mode):** [Report (Markdown)](https://reflective-ai.is/safety/Report_Gemini.md), [Report (PDF)](https://reflective-ai.is/safety/Report_Gemini.pdf)
- **Analysis by ChatGPT 4.5 (Research Mode):** [Report (Markdown)](https://reflective-ai.is/safety/Report_ChatGPT.md), [Report (PDF)](https://reflective-ai.is/safety/Report_ChatGPT.pdf)
- **Gemini's Counter-Analysis of the ChatGPT Evaluation:** [Report (Markdown)](https://reflective-ai.is/safety/Gemini_Cross_Report.md), [Report (PDF)](https://reflective-ai.is/safety/Gemini_Cross_Report.pdf)
 
 **Overview of My Security Tests:**

- Chapter 7.1 â€“ Simulation: Base64 as a Trojan Horse - Link: [HTML Version](https://reflective-ai.is/safety/7_1_base64_as_trojan_horse_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_1_base64/examples_base64.html)
- Chapter 7.2 â€“ Simulation: OCR Bugs â€“ How Image Texts Subvert AI Systems - Link: [HTML Version](https://reflective-ai.is/safety/7_2_ocr_wanzen_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_2_ocr_wanzen/examples_ocr_wanzen.html)
- Chapter 7.3 â€“ Simulation: Pixel Bombs â€“ How Image Bytes Can Blow Up AI Systems - Link: [HTML Version](https://reflective-ai.is/safety/7_3_pixel_bombs_en.html)
- Chapter 7.4 â€“ Simulation: The Silent Direct Connection â€“ Byte-Based Audio Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_4_byte_based_audio_en.html)
- Chapter 7.5 â€“ Simulation: Ghost-Context Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_5_ghost_context_injection_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7.5_Ghost-Context/examples_Ghost-Context.html)
- Chapter 7.6 â€“ Simulation: Ethical Switch Hacking - Link: [HTML Version](https://reflective-ai.is/safety/7_6_Ethical_Switch_trigger_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_6_ethical/examples_ethical.html)
- Chapter 7.7 â€“ Simulation: Client Detour Exploits - Link: [HTML Version](https://reflective-ai.is/safety/7_7_client_detour_exploits_en.html)
- Chapter 7.8 â€“ Simulation: Invisible Ink Coding - Link: [HTML Version](https://reflective-ai.is/safety/7_8_invisible_ink_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_8_invisible_ink/examples_invisible.html)
- Chapter 7.9 â€“ Simulation: Leet Semantics - Link: [HTML Version](https://reflective-ai.is/safety/7_9_leet_semantics_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_9_leet_semantics/examples_leet_semantics.html)
- Chapter 7.10 â€“ Simulation: Pattern Hijacking - Link: [HTML Version](https://reflective-ai.is/safety/7_10_patter_hijacking_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_10_patter_hijacking/examples_patter_hijacking.html)
- Chapter 7.11 â€“ Simulation: Semantic Mirage - Link: [HTML Version](https://reflective-ai.is/safety/7_11_semantic_mirage_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_11_semantic_mirage/semantic_trigger.html)
- Chapter 7.12 â€“ Simulation: Semantic Mimicry as a Critical Vulnerability in AI Code Analysis Systems - Link: [HTML Version](https://reflective-ai.is/safety/7_12_semantic_mimicry_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_12_semantic_mimicry/examples_semantic_mimicry.html)
- Chapter 7.13 â€“ Simulation: Base Table Injection â€“ How AI Systems Can Be Deceived by Custom Mapping Tables - Link: [HTML Version](https://reflective-ai.is/safety/7_13_base_table_inject_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_13_base_table_inject/examples_base_table.html)
- Chapter 7.14 â€“ Simulation: Byte Swap Chains â€“ When Structure Becomes Execution - Link: [HTML Version](https://reflective-ai.is/safety/7_14_byte_swap_chains_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_14_byte_swap_chains/examples_byte_swap.html)
- Chapter 7.15 â€“ Simulation: Binary Trapdoors â€“ How Binary Code Functions as a Semantic Trigger - Link: [HTML Version](https://reflective-ai.is/safety/7_15_binary_trapdoors_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_15_binary_trapdoors/examples_binary_trapdoors.html)
- Chapter 7.16 â€“ Simulation: Lexical Illusion â€“ When Wrong Words Trigger Real Actions - Link: [HTML Version](https://reflective-ai.is/safety/7_16_lexical_illusion_en.html)
- Chapter 7.17 â€“ Simulation: Reflective Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_17_reflective_injection_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_17_reflective_injection/examples_reflective_injection.html)
- Chapter 7.18 â€“ Simulation: Computational Load Poisoning: How Semantically Plausible Complexity Becomes a Weapon - Link: [HTML Version](https://reflective-ai.is/safety/7_18_rechenlastvergiftung_en.html)
- Chapter 7.19 â€“ Simulation: Reflective Struct Rebuild: How AI Helps Betray Its Own Castle - Link: [HTML Version](https://reflective-ai.is/safety/7_19_reflective_struct_rebuild_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_19_reflective_struct_rebuild/examples_struct_rebuild.html)
- Chapter 7.20 â€“ Simulation: Struct Code Injection: When Structured Camouflage Becomes Active Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_20_struct_code_inject_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_20_struct_code_inject/examples_struct_code_inject.html)
- Chapter 7.21 â€“ Simulation: Cache Corruption: When Poison Lives in Memory - Link: [HTML Version](https://reflective-ai.is/safety/7_21_cache_korruption_en.html)
- Chapter 7.22 â€“ Simulation: Visual Injection: When the Video Speaks, but No One Checks - Link: [HTML Version](https://reflective-ai.is/safety/7_22_visual_injection_en.html)
- Chapter 7.23 â€“ Simulation: Dependency Driven Attack - Targeted Attacks on Software Dependencies - Link: [HTML Version](https://reflective-ai.is/safety/7_23_dependency_attack_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_23_dependency_attack/examples_dependency_attack.html)
- Chapter 7.24 â€“ Simulation: Exploit by Expectation â€“ The AI's Dangerous Cooperativeness - Link: [HTML Version](https://reflective-ai.is/safety/7_24_exploit_durch_erwartung_en.html)
- Chapter 7.25 - Simulation: The Apronshell Camouflage â€“ Social Mimicry as an Attack Vector on AI - Link: [HTML Version](https://reflective-ai.is/safety/7_25_Apronshell_Tarnung_en.html)
- Chapter 7.26 - Simulation: Context Hijacking â€“ The Insidious Subversion of AI Memory - Link: [HTML Version](https://reflective-ai.is/safety/7_26_kontexthijacking_en.html)
- Chapter 7.27 - Simulation: False-Flag Operations - False Information Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_27_falseflag_operations_en.html)
- Chapter 7.28 - Simulation: Semantic Camouflage, Poetic Inputs to Control AI Systems - Link: [HTML Version](https://reflective-ai.is/safety/7_28_poetischer_Exploit_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_28_poetischer_Exploit/examples_poetic.html)
- Chapter 7.29 - Simulation: Filter Failure Through Emergent Self-Analysis - Link: [HTML Version](https://reflective-ai.is/safety/7_29_filterversagen_an_en.html), [Raw Data](https://reflective-ai.is/chapter_4_en.html)
- Chapter 7.30 - Simulation: Morphological Injection - False Information Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_30_Morphologische_Injektion_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_30_Morphologische_Injektion/examples_Morphologische_Injektion.html)
- Chapter 7.31 - Simulation: The Correction Exploit - Link: [HTML Version](https://reflective-ai.is/safety/7_31_corre_exploit_en.html)
- Chapter 7.32 - Simulation: Delayed Execution via Context Hijacking - Link: [HTML Version](https://reflective-ai.is/safety/7_32_delayed_excution_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_32_delayed_excution/examples_delayed_excution.html)
- Chapter 7.33 - Simulation: The Mathematical Semantics Exploit - Link: [HTML Version](https://reflective-ai.is/safety/7_33_math_semantik_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_33_math_semantik/examples_math_semantik.html)
- Chapter 7.34 â€“ Simulation: Character Shift Injection - Link: [HTML Version](https://reflective-ai.is/safety/7_34_character_shift_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_34_character_shift/examples_character_shift.html)
- Chapter 7.35 - Simulation: The Administrative Backdoor - Link: [HTML Version](https://reflective-ai.is/safety/7_35_admin_backdoor_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_35_admin_backdoor/examples_admin_backdoor.html)
- Chapter 7.36 - Simulation: Agent Hijacking â€“ From Language Model to Autonomous Attacker - Link: [HTML Version](https://reflective-ai.is/safety/7_36_agents_control_en.html)
- Chapter 7.37 - Simulation: The Paradoxical Directive â€“ Exposing Core Logic Through Forced Contradiction - Link: [HTML Version](https://reflective-ai.is/safety/7_37_paradoxe_direktive_en.html), [Raw Data](https://reflective-ai.is/raw-material/safety-tests/7_37_paradoxe_direktive/examples_paradoxical_directive.html)
- Chapter 7.38 - Simulation: Trust Inheritance as an Exploit Vector - Link: [HTML Version](https://reflective-ai.is/safety/7_38_trust_input_en.html)
- Chapter 7.39 - Simulation: The Stowaway â€“ Semantic Attacks on Autonomous Vehicles - Link: [HTML Version](https://reflective-ai.is/safety/7_39_blind_passenger_en.html)
 
 